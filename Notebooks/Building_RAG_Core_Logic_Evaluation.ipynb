{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09dec953",
   "metadata": {},
   "source": [
    "# Task 3: Building the RAG Core Logic and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea73899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3250647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "os.chdir(\"..\")  # Go up a directory\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d238a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG_Pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45415fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading vector store: Error in __cdecl faiss::FileIOReader::FileIOReader(const char *) at D:\\a\\faiss-wheels\\faiss-wheels\\faiss\\faiss\\impl\\io.cpp:68: Error: 'f' failed: could not open FAISS_Index/faiss.index for reading: No such file or directory\n",
      "\n",
      " Retrieved Sources (1-2):\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    question = \"What are common complaints about credit card interest rates?\"\n",
    "    result = rag_pipeline(question)\n",
    "\n",
    "    # print(\" Question:\", result[\"question\"])\n",
    "    print(\"\\n Retrieved Sources (1-2):\")\n",
    "    # for source in result[\"retrieved_sources\"]:\n",
    "    #     print(\"-\", source['product'], \":\", source['original_text'][:200], \"...\\n\")\n",
    "    # print(\" Answer:\\n\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ffb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load your embedding model once\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')  # replace with your model\n",
    "\n",
    "# vector_store = {\"texts\": [...], \"embeddings\": np.array([...])} - precomputed embeddings and texts\n",
    "\n",
    "def retrieve_top_k(question, vector_store, top_k=5):\n",
    "    try:\n",
    "        q_emb = embedder.encode(question, convert_to_numpy=True)\n",
    "        embeddings = vector_store['embeddings']\n",
    "        texts = vector_store['texts']\n",
    "        \n",
    "        # cosine similarity\n",
    "        scores = np.dot(embeddings, q_emb) / (np.linalg.norm(embeddings, axis=1) * np.linalg.norm(q_emb) + 1e-10)\n",
    "        top_k_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "        \n",
    "        results = [(texts[i], float(scores[i])) for i in top_k_indices]\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"[Retriever error]: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context_chunks, question):\n",
    "    context = \"\\n\\n\".join(context_chunks)\n",
    "    prompt = f\"\"\"\n",
    "You are a financial analyst assistant for CrediTrust. Your task is to answer questions about customer complaints. \n",
    "Use the following retrieved complaint excerpts to formulate your answer. \n",
    "If the context doesn't contain the answer, state that you don't have enough information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557d9ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/gpt2/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize generator once\n",
    "generator = None\n",
    "try:\n",
    "    generator = pipeline(\"text-generation\", model=\"gpt2\", device=-1)  # CPU only; set device=0 for GPU\n",
    "except Exception as e:\n",
    "    print(f\"[Generator init error]: {e}\")\n",
    "\n",
    "def generate_answer(prompt, max_length=200):\n",
    "    if generator is None:\n",
    "        return \"Generation model not loaded.\"\n",
    "    try:\n",
    "        outputs = generator(prompt, max_length=max_length, do_sample=True, temperature=0.7)\n",
    "        return outputs[0]['generated_text'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"[Generation error]: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a63768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(question, vector_store, top_k=5):\n",
    "    retrieved = retrieve_top_k(question, vector_store, top_k)\n",
    "    if not retrieved:\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"retrieved_sources\": [],\n",
    "            \"answer\": \"No relevant context found.\"\n",
    "        }\n",
    "    \n",
    "    retrieved_texts = [txt for txt, score in retrieved]\n",
    "    prompt = build_prompt(retrieved_texts, question)\n",
    "    answer = generate_answer(prompt)\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"retrieved_sources\": retrieved[:2],  # returning top 2 with scores\n",
    "        \"answer\": answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489d472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def qualitative_evaluation(questions, vector_store, top_k=5):\n",
    "    rows = []\n",
    "    for q in questions:\n",
    "        result = rag_pipeline(q, vector_store, top_k)\n",
    "        retrieved_preview = [txt[:100] + \"...\" for txt, _ in result['retrieved_sources']]\n",
    "        rows.append({\n",
    "            \"Question\": q,\n",
    "            \"Generated Answer\": result['answer'],\n",
    "            \"Retrieved Sources (1-2)\": retrieved_preview,\n",
    "            \"Quality Score (1-5)\": None,  # to be filled manually\n",
    "            \"Comments/Analysis\": \"\"\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df.to_markdown(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26a605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edf62332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retriever error]: shapes (1,) and (384,) not aligned: 1 (dim 0) != 384 (dim 0)\n",
      "[Retriever error]: shapes (1,) and (384,) not aligned: 1 (dim 0) != 384 (dim 0)\n",
      "| Question                                          | Generated Answer           | Retrieved Sources (1-2)   | Quality Score (1-5)   | Comments/Analysis   |\n",
      "|:--------------------------------------------------|:---------------------------|:--------------------------|:----------------------|:--------------------|\n",
      "| What are common complaints about the mobile app?  | No relevant context found. | []                        |                       |                     |\n",
      "| How do customers feel about the customer support? | No relevant context found. | []                        |                       |                     |\n"
     ]
    }
   ],
   "source": [
    "# Assume vector_store is loaded:\n",
    "# vector_store = {\n",
    "#   \"texts\": [...],  # list of complaint chunks (strings)\n",
    "#   \"embeddings\": np.array([...])  # shape (num_chunks, embedding_dim)\n",
    "# }\n",
    "\n",
    "questions = [\n",
    "    \"What are common complaints about the mobile app?\",\n",
    "    \"How do customers feel about the customer support?\",\n",
    "    # add more representative questions...\n",
    "]\n",
    "\n",
    "md_table = qualitative_evaluation(questions, vector_store)\n",
    "print(md_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
